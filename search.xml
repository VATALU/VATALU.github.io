<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[WebSocket 调研总结]]></title>
    <url>%2F2018%2F07%2F23%2FWebSocket%20%E8%B0%83%E7%A0%94%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[本文是将我 confluence 上的文章搬运过来，侧重于前后端实时通讯的横向比较以及 Spring-boot 资源的整理。 前后端实时通讯解决方案比较Web 为了实现即时通信，有以下几种方案，HTTP short-polling, HTTP long-polling, Streaming, Server-sent Events (SSE), WebSockets。下面会介绍以及比较各种方案的优劣。 HTTP short-polling每隔一段时间就自动发出一个 HTTP 请求给服务器。 这个是最老旧的方式，导致连接数会很多，并且每次发送的请求都会有 HTTP 的 Header，消耗流量。很显然对于服务器的压力大。 HTTP long-polling长轮询是对短轮询的改进版，客户端发送 HTTP 给服务器之后，如果没有消息就会阻塞到有消息或者超时了，才会返回给客户端。消息返回之后再建立连接，如此反复。 在某种程度上减小了网络带宽和 CPU 利用率等问题。这种方式会导致实时性不高，并且网络带宽利用率低的问题也没有从根源上解决。每个 Request 都会带相同的 Header。 StreamingIframe Streaming在页面中插入一个隐藏的 iframe, 利用其 src 属性在服务器和客户端之间创建一条长链接，服务器向 iframe 传输数据。 实现简单，但无法知道连接状态。 AJAX multipart streaming (XHR Streaming)实现思路：浏览器必须支持 multi-part 标志，客户端通过 AJAX 发出请求 Request，服务器保持住这个连接，然后可以通过 HTTP1.1 的 chunked encoding 机制（分块传输编码）不断 push 数据给客户端,直到 timeout 或者手动断开连接。 客户端一次连接，服务器数据可多次推送。但是并非所有浏览器都支持 XHR Streaming。 Flash Streaming通过内嵌使用了 Socket 类的 Flash 程序，JavaScript 通过调用此 Flash 程序提供的 Socket 接口与服务器端的 Socket 接口进行通信，JavaScript 通过 Flash Socket 接收到服务器端传送的数据。 缺点很明显，要装 Flash. Server-Sent Events服务器发送事件（SSE）也是 HTML5 公布的一种服务器向浏览器客户端发起数据传输的技术。一旦创建了初始连接，事件流将保持打开状态，直到客户端关闭。该技术通过传统的 HTTP 发送，并具有 WebSockets 缺乏的各种功能，例如自动重新连接、事件 ID 以及发送任意事件的能力。 SSE 就是利用服务器向客户端声明，接下来要发送的是流信息（streaming），会连续不断地发送过来。这时，客户端不会关闭连接，会一直等着服务器发过来的新的数据流，可以类比视频流。SSE 就是利用这种机制，使用流信息向浏览器推送信息。它基于 HTTP 协议，目前除了 IE/Edge，其他浏览器都支持。 SSE 是单向通道，只能服务器向浏览器发送，因为流信息本质上就是下载。 服务器向浏览器发送的 SSE 数据，必须是 UTF-8 编码的文本，具有如下的 HTTP 头信息。 Content-Type: text/event-stream Cache-Control: no-cache Connection: keep-alive 必须将 Content-Type 指定为 event-steam。 SSE 的优势 通过简单的 HTTP 传输，而不是自定义协议。 Can be poly-filled with JS to “backport” SSE to browsers that do not support it yet 支持重连 SSE 的劣势 不支持二进制传输 最大连接限制（每个浏览器仅限 6 个，并且不将会在 Chrome 和 Firefox 中修复） 单向 WebSocket WebSocket 是一种在单个 TCP 连接上进行全双工通讯的协议。WebSocket 使得客户端和服务器之间的数据交换变得更加简单，允许服务端主动向客户端推送数据。在 WebSocket API 中，浏览器和服务器只需要完成一次握手，两者之间就直接可以创建持久性的连接，并进行双向数据传输。—— By Wikipedia 过去，创建需要在客户端和服务之间双向通信的web应用，需要通过HTTP来轮询服务器来获取更新然后如果是推送消息则发送另一个请求。这样做会存在一些问题。 服务器端被迫提供两类接口，一类提供给客户端轮询新消息，一类提供给客户端推送消息给服务器端。 HTTP协议有较多的额外费用 (overhead)，每次发送消息都会有一个 HTTP header 信息，而且如果不用 Keep-Alive 每次还都要握手。 客户端的脚本比如JS可能还需要跟踪整个过程，也就是说我发送一个消息后，我可能需要跟踪这个消息的返回。一个简单的办法是使用单个 TCP 连接双向传输。这是为什么提供 WebSocket 协议。与 WebSocket API 结合，它提供了一个替代 HTTP 轮询的方式从 web 页面到远程服务器的双向通信。 一个简单的办法是使用单个 TCP 连接双向传输。这是为什么提供 WebSocket 协议。与 WebSocket API 结合，它提供了一个替代 HTTP 轮询的方式从 web 页面到远程服务器的双向通信。 Supported transports, by browser (html served from http:// or https://) Browser Websockets Streaming Polling IE 6, 7 no no jsonp-polling IE 8, 9 (cookies=no) no xdr-streaming &dagger; xdr-polling &dagger; IE 8, 9 (cookies=yes) no iframe-htmlfile iframe-xhr-polling IE 10 rfc6455 xhr-streaming xhr-polling Chrome 6-13 hixie-76 xhr-streaming xhr-polling Chrome 14+ hybi-10 / rfc6455 xhr-streaming xhr-polling Firefox &lt;10 no &Dagger; xhr-streaming xhr-polling Firefox 10+ hybi-10 / rfc6455 xhr-streaming xhr-polling Safari 5.x hixie-76 xhr-streaming xhr-polling Safari 6+ rfc6455 xhr-streaming xhr-polling Opera 10.70+ no &Dagger; iframe-eventsource iframe-xhr-polling Opera 12.10+ rfc6455 xhr-streaming xhr-polling Konqueror no no jsonp-polling WebSocket vs SSE实际上，所有能够用 SSE 实现的都可以用 WebSockets 替代，WebSockets 受到了更多的青睐并且也有更多的浏览器的支持。 但是 SSE 可以解决一些特定的业务并且后端也容易实现，SSE 也可以通过 JS polyfilled 不支持 SSE 的老浏览器。详见：Modernizr github page 所以应该对应不同的场景使用不同的技术。 SSE 使用场景： Stock ticker streaming twitter feed updating Notifications to browser WebSocket Protocol协议全文详见：RFC 6455 WebSocket 协议主要分为两个部分，一个是握手的规则，另一个是数据传输。 握手客户端发起请求，采用标准的 HTTP 报文，且仅支持 GET 方法，通过 HTTP Upgrade 机制升级协议至 WebSocket。这样的话只要使用 80/443 端口就可以了。 Sec-WebSocket-Version 客户端表明自己想要使用的版本号（一般都是 13 号版本），如果服务器不支持这个版本，则需要返回自己支持的版本。客户端拿到 Response 以后，需要对自己支持的版本号重新握手。这个 header 客户端必须要发送。 Sec-WebSocket-Key 客户端请求自动生成的一个 key。这个 header 客户端必须要发送。 Sec-WebSocket-Accept 服务器针对客户端的 Sec-WebSocket-Key 计算的响应值。这个 header 服务端必须要发送。 Sec-WebSocket-Protocol 用于协商应用子协议:客户端发送支持的协议列表，服务器必须只回应一个协议名。如果服务器一个协议都不能支持，直接握手失败。客户端可以不发送子协议，但是一旦发送，服务器无法支持其中任意一个都会导致握手失败。这个 header 客户端可选发送。 Sec-WebSocket-Extensions 用于协商本次连接要使用的 WebSocket 扩展:客户端发送支持的扩展，服务器通过返回相同的首部确认自己支持一或多个扩展。这个 header 客户端可选发送。服务端如果都不支持，不会导致握手失败，但是此次连接不能使用任何扩展。 WebSocket 协议扩展 多路复用扩展(A Multiplexing Extension for WebSockets)这个扩展可以通过握手时建立的 TCP 连接建立多条独立的逻辑上的 WebSocket ( logical connection )通道，每个虚拟的 WebSocket 通道以非零的 ID 标注，0 号通道为控制通道。 在 header 里添加 “Sec-WebSocket-Extensions: mux”开启多路复用扩展。在实际上的 WebSocket 连接建立的时候就会自动多开启一条 multiplexed connection。只有客户端通过 AddChannelRequest 才能够创建新的 logical WebSocket 连接。这样接受者就能 ( May ) 并行处理不同通道发送过来的 frames 了。 每个通道（除了控制通道）会分配一个定额来限制（默认 64 KB）每个 frame 的 Payload 大小。详文：A Multiplexing Extension for WebSockets 压缩扩展(Compression Extensions fos’sr WebSocket)给 WebSocket 协议增加了压缩功能。（例如 x-webkit-deflate-frame 扩展） 如果不进行多路复用扩展，每个 WebSocket 连接都只能独享专门的一个 TCP 连接，而且当遇到一个巨大的消息分成多个帧的时候，容易产生队首阻塞的情况。队首阻塞会导致延迟，所以分成多个帧能尽量的小是关键。不过在进行了多路复用扩展以后，多个连接复用一个 TCP 连接，每个信道依旧会存在队首阻塞的问题。除了多路复用，还要进行多路并行发送消息。 如果通过 HTTP2 进行 WebSocket 传输，性能会更好一点，毕竟 HTTP2 原生就支持了流的多路复用。利用 HTTP2 的分帧机制进行 WebSocket 的分帧，多个 WebSocket 可以在同一个会话中传输。 数据格式由一个或多个 Frame 组成。 frame 格式以及每个字段具体含义请参阅 RFC 文档。 数据传递一旦 WebSocket 客户端，服务端建立连接后，后续的操作都是基于数据帧的传递。 WebSocket 根据 opcode 来区分操作的类型。 连接保持 + 心跳客户端与服务端之间长时间没有数据往来，但仍然需要保持连接。这个时候，可以采用心跳来实现。 pingpongping, pong 对应的 opcode 分别是 0x9, 0xA。 关闭连接发送或接受一个 close 的 opcode 0x8. 启动 WebSocket 关闭阶段。如果一个终端在收到 close frame 之前没有发出 close frame, 那么这个终端就必须返回一个 close frame. 如果当前有正在传输的 frame, 那么 close frame 将会在这个 frame 传输结束后再发出。并不能保证终端在发出 close frame 后还能传输数据。 WebSocket 和 Proxy详文：【HTML5 Web Sockets 与代理服务器交互](http://www.infoq.com/cn/articles/Web-Sockets-Proxy-Servers) 可见全部走 secure 肯定是没问题的，使用 https 绕过中间代理，非 https 会导致 http 消息头丢失导致握手升级失败。 STOMP协议详见：STOMP STOMP 是属于消息队列的一种协议，很多 MQ 都已经支持。为浏览器和服务器之间的通信增加适当的消息语义。高层协议便于定义应用间所发送消息的语义。WebSocket 协议过于底层，并没有规定 payload 格式，而对于 Pub/Sub 模式，使用 STOMP 最合适不为过了。 STOMP Frame 格式COMMAND header1 : value1 header2 : value2 Body^@ STOMP 的优势：Use of STOMP as a sub-protocol enables the Spring Framework and Spring Security to provide a richer programming model vs using raw WebSockets. SockJS详情：SockJs ( Github – The MIT License ) SockJS 是一个 JS 库，它提供了一个类似于 WebSocket 的东西，SockJS 提供了一个连贯的、跨浏览器的 JS API, 他在浏览器和服务器之间创建了一个低延迟、全双工、跨域通信的通道。 SockJS 的一大好处在于提供了浏览器兼容性，优先使用 Native WebSocket, 在不支持 WebSocket 的浏览器中会自动降为各个浏览器专门的方式（streaming or polling）。一些浏览器缺少对于 WebSocket的支持，因此，回退选项是必要的，Spring 框架也提供了基于 SockJS 协议的透明回退选项。 SockJS 限制，SockJS 不允许对于一个域名同时打开多个 SockJS 连接。原因是 browsers don’t allow opening more than two outgoing connections to a single domain. 单个 SockJS session 需要两个连接——一个是下载数据，一个是发送信息。同时打开第二个 SockJS session 会阻塞。解决方法：使用子域名。 SockJS 也支持了 multiplex extension ：sockjs websocket-multiplex, How to do proper multiplexing on WebSockets or on SockJS Spring详文见：spring framework 5.0.0.BUILD-SNAPSHOT spring 4.x 就已经支持 WebSocket, STOMP, SockJS. Message QueueRabbitMQRabbitMQ Web STOMP Plugin Kafka自有一套协议 ActiveMQActiveMQ STOMP Protocol Support]]></content>
      <categories>
        <category>Material</category>
      </categories>
      <tags>
        <tag>network</tag>
        <tag>WebSocket</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[写在明天前]]></title>
    <url>%2F2018%2F07%2F19%2F%E5%86%99%E5%9C%A8%E6%98%8E%E5%A4%A9%E5%89%8D%2F</url>
    <content type="text"><![CDATA[实习了快两周了，差不多熟悉了我们组的情况了，想发发牢骚。 先说下技术栈，前端的话基础是 react + node.js, 也算是常用的了，用 yarn 包管理，由于是 Saas 公司，前端必定要用到 Web 3D 那块，WebGL 那块不是很懂。后端的话有远古的 spring framework，也有 spring-boot 1.5, DB 的话 Mysql 主数据库，MongoDB 为辅还有用 Redis 做的队列。然后就是 micro-service，还有 devops 那套运维部署的东西了。 接触下来周围的人很强，实在是太强了，我们组算上我两个实习生一共 11 个开发，这 9 个人里面竟然有 3 个全栈(本职后端)。组里的业务也是他们还有几位前端佬撑起来的，几位佬也是十分善良的带我这个菜鸡。然后自己这边的工作的话个人觉得比较闲而且根本上线不了，调研 WebSocket. 关于 WS 的协议框架博客也看了七七八八，感觉是一些沟通上的问题以及实在不了解业务场景的问题，感觉进度是慢了点。这两天在看业务代码，感受到了码农的艰辛，“我一急管他呢,随便撸两手代码”，“我不管的，先 run 起来再说”。赶着业务上线，就不能好好写代码，不能好好写代码，就充斥着难以维护的代码，使得整个系统处于危险的悬崖边上。但这也总比为了代码质量而上不了线好。整个行业都是这样的，晚一天上线，有可能就被竞品干掉了。 最后在抱怨下我所看到的问题吧 公司处于扩张状态，随着人数的增长，沟通成本大大增加 整个系统架构（不单单包括我们组的业务）也太不合理了 敏捷团队不敏捷 我们组的优势吧在于全栈，像类似 WS 协议层的东西，如果不是前后端都会，是很难推进的。如今前后端完全分离的态势导致了这一层的新技术推进起来困难。所以我是觉得前后端能够使用同一门语言开发是最合适不过的了，Kotlin 就能够做到这一点，前端翻译成 JS,后端翻译 JVM 字节码，然后中间的一些组件能够复用。就能够解决一些问题，把与网络连接的模块交给后端来写，是最合适不过的了，前端就可以更加关注前端的业务逻辑了。（以上是我的设想罢了，Kotlin 的轮子还是要自己造）]]></content>
      <categories>
        <category>Complaint</category>
      </categories>
      <tags>
        <tag>碎碎念</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[写在周一前]]></title>
    <url>%2F2018%2F07%2F06%2F%E5%86%99%E5%9C%A8%E5%91%A8%E4%B8%80%E5%89%8D%2F</url>
    <content type="text"><![CDATA[也罢，大二已经结束了，想写点东西。 从小到大，成绩最差的就是语文。无论是家庭环境的影响也好，后天的厌恶也罢，我始终是一个不善于说话的人。随着年龄的增长，这份我不看重的东西使我在很多地方吃了亏。对于我来说，表达出我的思维是个大问题，从语言上理解别人的思维也是个大问题。近段时间的遭遇对我有所打击，因为我发现语言能够将自己那么丁点的学识增加到1.25倍,也能将学识缩小到一半。动动嘴皮子就能看起来很厉害这是最气的。再者就是参加的各种比赛根本就是很可笑的东西，底下的评委不懂技术，只会看看PPT做的好不好，idea好不好，这与我侧重的代码实现，技术选择完全不相干，这也是最气的。 说实话逃避是很开心的，但实在是太虚无了，颓废的不像个样子。一个人想要废掉，只需要一堵墙和一根网线，如果能够再有个外卖电话就完美了，世界上最远的距离，就是从寝室到楼下拿外卖的距离。就这样子，一寝室四个人，打了半个月的 GTA，想起来还是很骇人的。 之后就是找实习的事情了，本来投了一两封简历杳无音讯再加上个人本身的确有非常多的东西不理解，很多东西没有学，算法更是什么都不会就打算好好修炼一波明年再说了，但是后来遇到一些贵人，我鬼使神差般的竟然获得了内推，随便摸了两下就过了面试，当面给了offer，下周一就上班了一刚。这结果是我没想到的，实在要多谢那两位贵人，要是网投，早没了，面试也暴露了我很大的问题，写个极其简单的树的算法都写的趔趄，这方面确实差的太多了。 再就是暑假学车的事情了，我也终于妥协了（大一的时候一直抱着学的太早最后生疏得成为本本族的想法），最后发现驾校根本就是个应试基地，开个倒车还能有口诀，我也是服了，在学生时代还是结束这一大类无聊的活动也好。说实话，开车还是很简单的，和搬砖一样，都是熟练工。 写下计划吧（制定计划这东西一定是幸存者偏差！），暑假学车，至少科二得过吧，算法么开始啃导论和紫书了，工程上的东西就靠着实习了，中间件的开发还是很憧憬的。 碎碎念完觉得心情好了好多。]]></content>
      <categories>
        <category>Complaint</category>
      </categories>
      <tags>
        <tag>碎碎念</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Servlet, Tomcat, Jetty, Netty, Mina 它们都是什么?]]></title>
    <url>%2F2018%2F06%2F01%2FServlet-Tomcat-Jetty-Netty-Mina-%E5%AE%83%E4%BB%AC%E9%83%BD%E6%98%AF%E4%BB%80%E4%B9%88%2F</url>
    <content type="text"><![CDATA[这些是 Java Web 当中经常听到的几个名词，那么这些名词的定义是什么？它们之间的关系是什么呢？本文就此展开讨论。 结论先说结论吧： Servlet是一种Java EE规范，Tomcat &amp; Jetty是Servlet容器，Tomcat包含了Servlet。Servlet本身并不能处理外部请求，需要Servlet容器的配合，Netty和MINA是网络框架，我们可以使用Netty造出自己类似Tomcat的web服务器。简单的关系的话 Tomcat = Jetty &gt; Netty &amp; MINA &gt; Servlet。 Servlet wiki上的定义： Servlet 是用 Java 编写的服务器端程序。其主要功能在于交互式地浏览和修改数据，生成动态 Web 内容。狭义的 Servlet 是指 Java 语言实现的一个接口，广义的 Servlet 是指任何实现了这个 Servlet 接口的类，一般情况下，人们将 Servlet 理解为后者。 Tomcatwiki的定义： Tomcat 是由 Apache 软件基金会下属的 Jakarta 项目开发的一个 Servlet 容器，按照 Sun Microsystems 提供的技术规范，实现了对 Servlet 和 JavaServer Page（JSP） 的支持，并提供了作为 Web 服务器的一些特有功能，如 Tomcat 管理和控制平台、安全域管理和 Tomcat 阀等。由于 Tomcat 本身也内含了一个 HTTP 服务器，它也可以被视作一个单独的 Web 服务器。但是，不能将 Tomcat 和 Apache HTTP 服务器混淆，Apache HTTP 服务器是一个用C语言实现的 HTTPWeb服务器；这两个 HTTP web server 不是捆绑在一起的。Apache Tomcat 包含了一个配置管理工具，也可以通过编辑XML格式的配置文件来进行配置。 wiki 上跟进的很快也改成 Jakarta 了。 Jettywiki的定义： Jetty是一个纯粹的基于Java的网页服务器和Java Servlet容器。尽管网页服务器通常用来为人们呈现文档，但是Jetty通常在较大的软件框架中用于计算机与计算机之间的通信。Jetty作为Eclipse基金会的一部分，是一个自由和开源项目。该网页服务器被用在Apache ActiveMQ[2]、Alfresco[3]、Apache Geronimo[4]、Apache Maven、Apache Spark、Google App Engine[5]、Eclipse[6]、FUSE[7]、Twitter’s Streaming API[8]、Zimbra[9]等产品上。Jetty也是Lift、Eucalyptus、Red5、Hadoop、I2P等开源项目的服务器。[10] Jetty支持最新的Java Servlet API（带JSP的支持），支持SPDY和WebSocket协议。 Nettywiki的定义： Netty is a non-blocking I/O client-server framework for the development of Java network applications such as protocol servers and clients. The asynchronous event-driven network application framework and tools are used to simplify network programming such as TCP and UDP socket servers.[2] Netty includes an implementation of the reactor pattern of programming. 翻译如下： Netty是一个基于NIO客户端-服务端框架，提供给诸如协议服务端与客户端的Java网络应用。异步事件驱动网络应用框架和工具用来简化TCP和UDP网络编程。Netty包括了一种响应式编程的实现。 Minawiki的定义： Apache MINA (Multipurpose Infrastructure for Network Applications)[1] is an open source Java network application framework. MINA can be used to create scalable, high performance network applications. MINA provides unified APIs for various transports like TCP, UDP, serial communication. It also makes it easy to make an implementation of custom transport type. MINA provides both high-level and low-level network APIs. 翻译如下 Apache MINA 是一个开源Java网络应用框架。MINA可以创建表现良好的网络应用。MINA为各中通讯机制比如TCP,UDP提供统一的API。并且也可以很方便的实现一个自定义通讯方案。MINA提供高层和底层的API。 关系Servlet 一种规范Servlet是并不是对网络服务器的封装，而是JEE规范当中的一个。所以它可以支持多层用户协议。 Tomcat &amp; Jetty 轻量级服务器它们俩是同一级别的，都是Servlet容器。对于Servlet容器的工作机制这里有一篇很棒的blog Servlet 工作原理解析 Netty &amp; MINA 网络编程框架Netty是基于NIO的，Netty也像wiki介绍中说的Netty在很多大型项目中使用，之前文章中的 ElasticSearch transport也使用了Netty。MINA也是NIO框架，和Netty处于同一级别。下面是它们的区别： mina比netty出现的早，都是Trustin Lee的作品； mina将内核和一些特性的联系过于紧密，使得用户在不需要这些特性3的时候无法脱离，相比下性能会有所下降；netty解决了这个设计问题； netty的文档更清晰，很多mina的特性在netty里都有； netty更新周期更短，新版本的发布比较快； 它们的架构差别不大，mina靠apache生存，而netty靠jboss，和jboss的结合度非常高，netty有对google protocal buf的支持，有更完整的ioc容器支持(spring,guice,jbossmc和osgi)； netty比mina使用起来更简单，netty里你可以自定义的处理upstream events 或/和 downstream events，可以使用decoder和encoder来解码和编码发送内容； netty和mina在处理UDP时有一些不同，netty将UDP无连接的特性暴露出来；而mina对UDP进行了高级层次的抽象，可以把UDP当成”面向连接”的协议，而要netty做到这一点比较困难。mina把TCP和UDP一样当”有连接”的处理，一个UDP请求会按照address产生一个新的 IoSession，过期时间是1分钟，这样做的好处是显然的，但是对于有性能要求的项目就不好了，对一个无连接的东西cache 1分钟，大多数时候可能是白cache了，做无用功。 Mina这样做可能还有个初衷是连续解码用的，比如一个包太大了，分了两次传输；但是这样的设计应该是udp大忌了。]]></content>
      <categories>
        <category>Material</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>web</tag>
        <tag>server</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Reactor 3 参考文档阅读笔记]]></title>
    <url>%2F2018%2F05%2F28%2FReactor-3-%E5%8F%82%E8%80%83%E6%96%87%E6%A1%A3%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[本文将记录笔者Reactor 3 文档中文翻译 的阅读笔记。 快速上手Flux 用于 N 个元素， Mono用于 0/1 个元素。 响应式编程阻塞是对资源的浪费 并行化：使用更多的线程和硬件资源 基于现有的资源来提高效率 异步可以解决问题吗?两种异步编程方式 回调 (回调地狱) Futures (对于多个处理的组合不好用，get()方法仍然会阻塞且缺乏对多个值以及更进一步对错误的处理。) 反正这里就是说：Reactor一级棒 从命令式编程到响应式编程 Reactor 这样的响应式编程库就是要弥补上述“经典”的 JVM 异步方式所带来的不足。 可编排性（Composability） 以及 可读性（Readability） 使用丰富的 操作符 来处理形如 流 的数据 在 订阅（subscribe） 之前什么都不会发生 背压（backpressure） 具体来说即 消费者能够反向告知生产者生产内容的速度的能力 高层次 （同时也是有高价值的）的抽象，从而达到 并发无关 的效果 可编排性与可读性 可编排性，指的是编排多个异步任务的能力。比如我们将前一个任务的结果传递给后一个任务作为输入， 或者将多个任务以分解再汇总（fork-join）的形式执行，或者将异步的任务作为离散的组件在系统中 进行重用。 Reactor 提供了丰富的编排操作，从而代码直观反映了处理流程，并且所有的操作保持在同一层次 （尽量避免了嵌套）。 就像装配流水线 你可以想象数据在响应式应用中的处理，就像流过一条装配流水线。Reactor 既是传送带， 又是一个个的装配工或机器人。原材料从源头（最初的 Publisher）流出，最终被加工为成品， 等待被推送到消费者（或者说 Subscriber）。 原材料会经过不同的中间处理过程，或者作为半成品与其他半成品进行组装。如果某处有齿轮卡住， 或者某件产品的包装过程花费了太久时间，相应的工位就可以向上游发出信号来限制或停止发出原材料。 这两段比喻可以说时很形象了，从代码角度.两下就完事了。 操作符 在 Reactor 中，操作符（operator）就像装配线中的工位（操作员或装配机器人）。每一个操作符 对 Publisher 进行相应的处理，然后将 Publisher 包装为一个新的 Publisher。就像一个链条， 数据源自第一个 Publisher，然后顺链条而下，在每个环节进行相应的处理。最终，一个订阅者 (Subscriber）终结这个过程。请记住，在订阅者（Subscriber）订阅（subscribe）到一个 发布者（Publisher）之前，什么都不会发生。 subscribe()之前什么都不会发生 在 Reactor 中，当你创建了一条 Publisher 处理链，数据还不会开始生成。事实上，你是创建了 一种抽象的对于异步处理流程的描述（从而方便重用和组装）。 当真正“订阅（subscrib）”的时候，你需要将 Publisher 关联到一个 Subscriber 上，然后 才会触发整个链的流动。这时候，Subscriber 会向上游发送一个 request 信号，一直到达源头 的 Publisher。 背压 向上游传递信号这一点也被用于实现 背压 ，就像在装配线上，某个工位的处理速度如果慢于流水线 速度，会对上游发送反馈信号一样。 热 vs 冷在 Rx 家族的响应式库中，响应式流分为“热”和“冷”两种类型，区别主要在于响应式流如何 对订阅者进行响应： 一个“冷”的序列，指对于每一个 Subscriber，都会收到从头开始所有的数据。如果源头 生成了一个 HTTP 请求，对于每一个订阅都会创建一个新的 HTTP 请求。 一个“热”的序列，指对于一个 Subscriber，只能获取从它开始 订阅 之后 发出的数据。不过注意，有些“热”的响应式流可以缓存部分或全部历史数据。 通常意义上来说，一个“热”的响应式流，甚至在即使没有订阅者接收数据的情况下，也可以 发出数据（这一点同 “Subscribe() 之前什么都不会发生”的规则有冲突）。 Reactor核心特性 Reactor 项目的主要 artifact 是 reactor-core，这是一个基于 Java 8 的实现了响应式流规范 （Reactive Streams specification）的响应式库。 简单的创建和订阅Flux或Mono的方法Flux 和 Mono 提供的工厂方法123456789Flux&lt;String&gt; seq1 = Flux.just("foo", "bar", "foobar");List&lt;String&gt; iterable = Arrays.asList("foo", "bar", "foobar");Flux&lt;String&gt; seq2 = Flux.fromIterable(iterable);Mono&lt;String&gt; noData = Mono.empty(); Mono&lt;String&gt; data = Mono.just("foo");Flux&lt;Integer&gt; numbersFromFiveToSeven = Flux.range(5, 3); 基于lambda的对Flux的订阅 1subscribe(); 订阅并触发序列 1subscribe(Consumer&lt;? super T&gt; consumer); 对每个生成的元素进行消费 12subscribe(Consumer&lt;? super T&gt; consumer, Consumer&lt;? super Throwable&gt; errorConsumer); 对正常元素进行消费，也对错误进行响应。 123subscribe(Consumer&lt;? super T&gt; consumer, Consumer&lt;? super Throwable&gt; errorConsumer, Runnable completeConsumer); 对正常元素和错误均有响应，还定义了序列正常完成后的回调 1234subscribe(Consumer&lt;? super T&gt; consumer, Consumer&lt;? super Throwable&gt; errorConsumer, Runnable completeConsumer, Consumer&lt;? super Subscription&gt; subscriptionConsumer); 对正常元素、错误和完成信号均有响应，同时也定义了对该subscribe方法返回的Subscription执行的回调 以上方法会返回一个 Subscription 的引用，如果不再需要更多元素你可以通过它来取消订阅。 取消订阅时， 源头会停止生成新的数据，并清理相关资源。取消和清理的操作在 Reactor 中是在 接口 Disposable 中定义的。 subscribe方法示例1Flux&lt;Integer&gt; ints = Flux.range(1, 3); 配置一个在订阅的时候产生3个值得Flux。 1ints.subscribe(); 最简单得订阅方式。 第二行代码没有任何输出，但是它确实执行了。Flux 产生了3个值。如果我们传入一个 lambda， 我们就可以看到这几个值，如下一个列子： 1Flux&lt;Integer&gt; ints = Flux.range(1, 3); 配置一个在订阅时会产生3个值得Flux。 1ints.subscribe(i -&gt; System.out.println(i)); 订阅它并打印值。 == 待续 ==]]></content>
      <categories>
        <category>Material</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Reactor</tag>
        <tag>Functional Program</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 一组常量应该如何存储？]]></title>
    <url>%2F2018%2F05%2F28%2FJava-%E4%B8%80%E7%BB%84%E5%B8%B8%E9%87%8F%E5%BA%94%E8%AF%A5%E5%A6%82%E4%BD%95%E5%AD%98%E5%82%A8%EF%BC%9F%2F</url>
    <content type="text"><![CDATA[在 Java 当中用哪种方式储存一组常量比较合理呢？是使用常量接口、常量类还是枚举类型呢？ 先说结论：定义常量不要使用接口常量，要在类中定义，使用 final 类以及 private 构造方法，如果常量可以进行归类，最好使用枚举定义：枚举 &gt; 类 &gt; 接口。 第一种：使用接口 1234public interface Constants &#123; public static final int AUDIT_STATUS_PASS = 1; public static final int AUDIT_STATUS_NOT_PASS = 2;&#125; 使用接口来保存常量的话会产生一些问题，常量接口是一种严重的反模式行为，《Effective Java》这么写道： The constant interface pattern is a poor use of interfaces. That a class uses some constants internally is an implementation detail. Implementing a constant interface causes this implementation detail to leak into the class’s exported API. It is of no consequence to the users of a class that the class implements a constant interface. In fact, it may even confuse them. Worse, it represents a commitment: if in a future release the class is modified so that it no longer needs to use the constants, it still must implement the interface to ensure binary compatibility. If a nonfinal class implements a constant interface, all of its subclasses will have their namespaces polluted by the constants in the interface. 翻译如下： 常量接口模式是对接口的不良使用。类在内部使用某些常量，这纯粹是实现细节。实现常量接口会导致把这样的实现细节泄露到该类的导出API中。类实现常量接口，这对于类的用户来讲并没有什么价值。实际上，这样做反而会使他们更加糊涂。更糟糕的是，它代表了一种承诺：如果在将来的发行版本中，这个类被修改了，它不再需要使用这些常量了，它依然必须实现这个接口，以确保兼容性。如果非final类实现了常量接口，它的所有子类的命名空间也会被接口中的常量所“污染”。 总结下： 接口是不能阻止被实现或继承的，也就是说子接口或实现中是能够覆盖掉常量的定义，这样通过父，子接口(或实现) 去引用常量是可能不一致的 同样的，由于被实现或继承，造成在继承树中可以用大量的接口, 类 或实例去引用 同一个常量，从而造成接口中定义的常量污染了命名空间。(Java 编译器竟然允许使用实例去引用类变量) 接口暗含的意思是：它是需被实现的，代表着一种类型，它的公有成员是要被暴露的 API。而在接口中定义的常量说不上是 API 第二种：使用类 123456public final class Constans&#123; public static final int AUDIT_STATUS_PASS = 1; public static final int AUDIT_STATUS_NOT_PASS = 2; //私有的构造方法 private Constans()&#123;&#125;;&#125; 添加 final 关键字来避免被继承，隐藏构造方法防止实例化，常量类解决了这两个问题，常量类会比常量接口编译出来的源文件字节多一点点。 第三种：使用枚举 12345678910111213141516171819public enum Constants &#123; AUDIT_STATUS_PASS(1), AUDIT_STATUS_NOT_PASS(2); private int status; private Constants(int status)&#123; this.setStatus(status); &#125; public int getStatus() &#123; return status; &#125; public void setStatus(int status) &#123; this.status = status; &#125; &#125; 《Effective Java》中有这么一个例子 123456public static final int APPLE_FUJI = 0;public static final int APPLE_PIPPIN = 1;public static final int APPLE_GRANNY_SMITH = 2;public static final int ORANGE_NAVEL = 0;public static final int ORANGE_TEMPLE = 1;public static final int ORANGE_BLOOD = 2; 针对int常量以下不足： 在类型安全方面，如果你想使用的是ORANGE_NAVEL，但是传递的是APPLE_FUJI，编译器并不能检测出错误； 因为int常量是编译时常量，被编译到使用它们的客户端中。若与枚举常量关联的int发生了变化，客户端需重新编译，否则它们的行为就不确定； 没有便利方法将int常量翻译成可打印的字符串。这里的意思应该是比如你想调用的是ORANGE_NAVEL，debug的时候显示的是0，但你不能确定是APPLE_FUJI还是ORANGE_NAVEL 如果你想使用String常量，虽然提供了可打印的字符串，但是性能会有影响。特殊是对于有些新手开发，有可能会直接将String常量硬编码到代码中，导致以后修改很困难。 所有这一切，enum都给出了具体的解决。唯一的缺点只是需要增加enum加载和实例化的时间。 以上面的 APPLE,ORANGE为例，用 enum 重写： 1234针对int常量以下不足： 1. 在类型安全方面，如果你想使用的是 ORANGE_NAVEL，但是传递的是 APPLE_FUJI，编译器并不能检测出错误； 2. 因为 int 常量是编译时常量，被编译到使用它们的客户端中。若与枚举常量关联的 int 发生了变化，客户端需重新编译，否则它们的行为就不确定； 3. 没有便利方法将 int 常量翻译成可打印的字符串。这里的意思应该是比如你想调用的是 ORANGE_NAVEL，debug 的时候显示的是 0，但你不能确定是 APPLE_FUJI 还是 ORANGE_NAVEL 如果你想使用 String 常量，虽然提供了可打印的字符串，但是性 能会有影响。特殊是对于有些新手开发，有可能会直接将String常量硬编码到代码中，导致以后修改很困难。 所有这一切，enum 都给出了具体的解决。唯一的缺点只是需要增加enum 加载和实例化的时间。]]></content>
      <categories>
        <category>Material</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IPv6 with Docker中文翻译]]></title>
    <url>%2F2018%2F01%2F30%2FIPv6-with-Docker%E4%B8%AD%E6%96%87%E7%BF%BB%E8%AF%91%2F</url>
    <content type="text"><![CDATA[老师的项目要在Ipv6环境下跑，结果发现中文版却并没有对此篇文章的翻译，本瓜皮就来翻译一下。原文地址 The information in this section explains IPv6 with the Docker default bridge. This is a bridge network named bridge created automatically when you install Docker. 这篇文章通过 Docker default bridge 来解释 IPv6 。这是一个 bridge 网络在你安装 Docker 的时候就自动创建。 As we are running out of IPv4 addresses the IETF has standardized an IPv4 successor, Internet Protocol Version 6 , in RFC 2460. Both protocols, IPv4 and IPv6, reside on layer 3 of the OSI model. 当我们的 IPv4 地址用尽的时候，IETF 在 RFC 2460 已经制定了一个 IPv4 的继承者———— IPv6，这两个协议都位于 OSI model(Open Systems Interconnection model) 的第三层。 How IPv6 works on Docker By default, the Docker server configures the container network for IPv4 only. You can enable IPv4/IPv6 dualstack support by running the Docker daemon with the –ipv6 flag. Docker will set up the bridge docker0 with the IPv6 link-local address fe80::1. 默认情况下， Docker server 只配置了这个容器的 IPv4 网络. 你可以同时使用 IPv4/IPv6 通过添加 –ipv6 执行 Docker 进程 。Docker 会设置 bridge docker0 通过 IPv6 链接本地地址 fe80::1。 By default, containers that are created will only get a link-local IPv6 address. To assign globally routable IPv6 addresses to your containers you have to specify an IPv6 subnet to pick the addresses from. Set the IPv6 subnet via the –fixed-cidr-v6 parameter when starting Docker daemon: 默认情况下，创建的容器只会得到一个链接本地 Ipv6 地址。为了能够分配可全球路由的 IPv6 地址给你的容器，你不得不指定一个 IPv6 子网去建立地址表。当 Docker 进程启动时，通过 –fixed-cidr-v6 参数设置 IPv6 子网。 1dockerd --ipv6 --fixed-cidr-v6="2001:db8:1::/64" The subnet for Docker containers should at least have a size of /80. This way an IPv6 address can end with the container’s MAC address and you prevent NDP neighbor cache invalidation issues in the Docker layer. Docker 容器的子网至少具有 /80 的形式。这样 IPv6 地址就能够以容器的 MAC 地址结尾并且防止在 Docker 层 NDP 缓存失效问题。 With the –fixed-cidr-v6 parameter set Docker will add a new route to the routing table. Further IPv6 routing will be enabled (you may prevent this by starting dockerd with –ip-forward=false): 通过 –fixed-cidr-v6 参数设置 Docker 会在路由表增加一个新路由。更多的 IPv6 路由将会启用（你通过用 –ip-forward=false 启动 Docker 来防止这种事情的发生） 12345$ ip -6 route add 2001:db8:1::/64 dev docker0$ sysctl net.ipv6.conf.default.forwarding=1$ sysctl net.ipv6.conf.all.forwarding=1 All traffic to the subnet 2001:db8:1::/64 will now be routed via the docker0 interface. 所有到 2001:db8:1::/64 子网的路由都会通过 docker0 接口路由。 Be aware that IPv6 forwarding may interfere with your existing IPv6 configuration: If you are using Router Advertisements to get IPv6 settings for your host’s interfaces you should set accept_ra to 2. Otherwise IPv6 enabled forwarding will result in rejecting Router Advertisements. E.g., if you want to configure eth0 via Router Advertisements you should set: 请注意 IPv6 转发会与 现存的 IPv6 配置连接：如果你正使用路由器广播来为你的主机接口获得 IPv6 设置，你应该设置 accept_ra=2 。否则 IPv6 转发会导致拒绝路由器广播。比如，如果你想配置 eth0 通过路由器广播，你应该这么设置。 1$ sysctl net.ipv6.conf.eth0.accept_ra=2 Every new container will get an IPv6 address from the defined subnet. Further a default route will be added on eth0 in the container via the address specified by the daemon option –default-gateway-v6 if present, otherwise via fe80::1: 所有的容器都会从定义的子网获得一个 IPv6 地址。一个默认的路由将会增加到 eth0 如果存在进程选项 –default-gateway-v6，通过被特定化的地址，否则默认通过 fe80::1: 1234567891011docker run -it ubuntu bash -c "ip -6 addr show dev eth0; ip -6 route show"15: eth0: &lt;BROADCAST,UP,LOWER_UP&gt; mtu 1500 inet6 2001:db8:1:0:0:242:ac11:3/64 scope global valid_lft forever preferred_lft forever inet6 fe80::42:acff:fe11:3/64 scope link valid_lft forever preferred_lft forever2001:db8:1::/64 dev eth0 proto kernel metric 256fe80::/64 dev eth0 proto kernel metric 256default via fe80::1 dev eth0 metric 1024 In this example the Docker container is assigned a link-local address with the network suffix /64 (here: fe80::42:acff:fe11:3/64) and a globally routable IPv6 address (here: 2001:db8:1:0:0:242:ac11:3/64). The container will create connections to addresses outside of the 2001:db8:1::/64 network via the link-local gateway at fe80::1 on eth0. 在这个例子当中 Docker 容器通过网络后缀 /64 (here: fe80::42:acff:fe11:3/64)和一个全局 IPv6 路由地址(here: 2001:db8:1:0:0:242:ac11:3/64)被分配了一个本地链接地址。通过这个本地链接网关 fe80::1，这个容器将会创造通往 2001:db8:1::/64 之外的网络地址连接。 Often servers or virtual machines get a /64 IPv6 subnet assigned (e.g. 2001:db8:23:42::/64). In this case you can split it up further and provide Docker a /80 subnet while using a separate /80 subnet for other applications on the host: 通常服务器或者虚拟机得到一个 /64 IPv6 子网分配 (比如： 2001:db8:23:42::/64)。当你想要给别的主机上的应用使用单独的 /80 子网，你可以分开它并提供给 Docker /80 子网 In this setup the subnet 2001:db8:23:42::/64 with a range from 2001:db8:23:42:0:0:0:0 to 2001:db8:23:42:ffff:ffff:ffff:ffff is attached to eth0, with the host listening at 2001:db8:23:42::1. The subnet 2001:db8:23:42:1::/80 with an address range from 2001:db8:23:42:1:0:0:0 to 2001:db8:23:42:1:ffff:ffff:ffff is attached to docker0 and will be used by containers. 2001:db8:23:42::/64 子网从 2001:db8:23:42:0:0:0:0 到 2001:db8:23:42:ffff:ffff:ffff:ffff 被赋给 eth0，在 2001:db8:23:42::1 被监听。子网 2001:db8:23:42:1::/80 从 2001:db8:23:42:1:0:0:0 to 2001:db8:23:42:1:ffff:ffff:ffff 将会被赋给 docker0 并且将会被容器使用。 Using NDP proxying If your Docker host is the only part of an IPv6 subnet but does not have an IPv6 subnet assigned, you can use NDP proxying to connect your containers to the internet via IPv6. If the host with IPv6 address 2001:db8::c001 is part of the subnet 2001:db8::/64 and your IaaS provider allows you to configure the IPv6 addresses 2001:db8::c000 to 2001:db8::c00f, your network configuration may look like the following: 如果你的 Docker 主机仅是唯一的 IPv6 子网，没有 IPv6 子网被分配，你可以用 NDP peoxying 去连接你的容器到网络。如果主机有着 2001:db8::c001 地址是 2001:db8::/64 的一部分并且你的 IaaS 提供商允许你配置 IPv6 地址 2001:db8::c000 ~ 2001:db8::c00f，你的网络配置应像下面一样。 12345678910$ ip -6 addr show1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 inet6 ::1/128 scope host valid_lft forever preferred_lft forever2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qlen 1000 inet6 2001:db8::c001/64 scope global valid_lft forever preferred_lft forever inet6 fe80::601:3fff:fea1:9c01/64 scope link valid_lft forever preferred_lft forever To slit up the configurable address range into two subnets 2001:db8::c000/125 and 2001:db8::c008/125, use the following daemon.json settings. The first subnet is used by non-Docker processes on the host, and the second is used by Docker. 将配置的地址分开成 2001:db8::c000/125 与 2001:db8::c008/125，用下面的 daemon.json。第一个子网会被用在主机上，而第二个会被 Docker 使用。 1234&#123; "ipv6": true, "fixed-cidr-v6": "2001:db8::c008/125"&#125; The Docker subnet is within the subnet managed by your router and connected to eth0. All containers with addresses assigned by Docker are expected to be found within the router subnet, and the router can communicate with these containers directly. Docker 子网被路由管理并且连接到 eth0。所有的具有这个地址的容器被 Docker 分配并且会在路由的子网里被找到。路由器可以和这些容器直接通信。 IPv6 NDP proxying When the router wants to send an IPv6 packet to the first container, it transmits a neighbor solicitation request, asking “Who has 2001:db8::c009?” However, no host on the subnet has the address; the container with the address is hidden behind the Docker host. The Docker host therefore must listen for neighbor solicitation requests and respond that it is the device with the address. This functionality is called the NDP Proxy and is handled by the kernel on the host machine. To enable the NDP proxy, execute the following command: 1$ sysctl net.ipv6.conf.eth0.proxy_ndp=1 Next, add the container’s IPv6 address to the NDP proxy table: 1$ ip -6 neigh add proxy 2001:db8::c009 dev eth0 From now on, the kernel answers neighbor solicitation addresses for this address on the device eth0. All traffic to this IPv6 address is routed through the Docker host, which forwards it to the container’s network according to its routing table via the docker0 device: 1234$ ip -6 route show2001:db8::c008/125 dev docker0 metric 12001:db8::/64 dev eth0 proto kernel metric 256 Execute the ip -6 neigh add proxy … command for every IPv6 address in your Docker subnet. Unfortunately there is no functionality for adding a whole subnet by executing one command. An alternative approach would be to use an NDP proxy daemon such as ndppd. Docker IPv6 clusterSwitched network environment Using routable IPv6 addresses allows you to realize communication between containers on different hosts. Let’s have a look at a simple Docker IPv6 cluster example: IPv6 switched network example The Docker hosts are in the 2001:db8:0::/64 subnet. Host1 is configured to provide addresses from the 2001:db8:1::/64 subnet to its containers. It has three routes configured: Route all traffic to 2001:db8:0::/64 via eth0 Route all traffic to 2001:db8:1::/64 via docker0 Route all traffic to 2001:db8:2::/64 via Host2 with IP 2001:db8::2 Host1 also acts as a router on OSI layer 3. When one of the network clients tries to contact a target that is specified in Host1’s routing table Host1 forwards the traffic accordingly. It acts as a router for all networks it knows: 2001:db8::/64, 2001:db8:1::/64, and 2001:db8:2::/64. On Host2 we have nearly the same configuration. Host2’s containers gets IPv6 addresses from 2001:db8:2::/64. Host2 has three routes configured: Route all traffic to 2001:db8:0::/64 via eth0 Route all traffic to 2001:db8:2::/64 via docker0 Route all traffic to 2001:db8:1::/64 via Host1 with IP 2001:db8:0::1 The difference to Host1 is that the network 2001:db8:2::/64 is directly attached to Host2 via its docker0 interface whereas Host2 reaches 2001:db8:1::/64 via Host1’s IPv6 address 2001:db8::1. This way every container can contact every other container. The containers Container1- share the same subnet and contact each other directly. The traffic between Container1- and Container2-* are routed via Host1 and Host2 because those containers do not share the same subnet. In a switched environment every host needs to know all routes to every subnet. You always need to update the hosts’ routing tables once you add or remove a host to the cluster. Every configuration in the diagram that is shown below the dashed line is handled by Docker: The docker0 bridge IP address configuration, the route to the Docker subnet on the host, the container IP addresses and the routes on the containers. The configuration above the line is up to the user and can be adapted to the individual environment.]]></content>
      <categories>
        <category>Material</category>
      </categories>
      <tags>
        <tag>Docker</tag>
        <tag>network</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch-6.0.0在Centos 7.3上部署]]></title>
    <url>%2F2017%2F12%2F31%2Felasticsearch%E5%9C%A8Centos%E4%B8%8A%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[本文介绍了 elasticsearch 是什么以及如何在 Centos 上部署。 Elasticsearch简介来自百度的介绍 ElasticSearch是一个基于Lucene的搜索服务器。它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful web接口。Elasticsearch是用Java开发的，并作为Apache许可条款下的开放源码发布，是当前流行的企业级搜索引擎。设计用于云计算中，能够达到实时搜索，稳定，可靠，快速，安装使用方便。我们建立一个网站或应用程序，并要添加搜索功能，但是想要完成搜索工作的创建是非常困难的。我们希望搜索解决方案要运行速度快，我们希望能有一个零配置和一个完全免费的搜索模式，我们希望能够简单地使用JSON通过HTTP来索引数据，我们希望我们的搜索服务器始终可用，我们希望能够从一台开始并扩展到数百台，我们要实时搜索，我们要简单的多租户，我们希望建立一个云的解决方案。因此我们利用Elasticsearch来解决所有这些问题以及可能出现的更多其它问题。 自己的理解 就是一个基于Lucene自带分布式的非常像Nosql的搜索引擎/结构化数据库(并不支持数据库的join操作)，基于HTTP协议通过 RESTful API, 传输Json数据提供稳定，可靠的搜索服务 Elasticsearch 相关资料 elastic官网 elastic文档 elastic中文文档 kibana指南 ik中文分词器 部署安装Java安装通过yum进行安装,先搜索合适的版本 yum search java|grep jdk 选择版本安装 yum install java-1.8.0-openjdk 然后配置环境变量 Elasticsearch安装下载elasticsearch-6.0.0 wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.0.0.tar.gz 解压elasticsearch tar -zxvf elasticsearch-6.0.0.tar.gz 做完这一步请先浏览下一节的elasticsearch配置，改变插件等安装的位置。 Kibana安装kibana的安装方法与elasticsearch，注意版本号应与elasticsearch相同，kibana是一个可视化数据管理工具，你可以在服务器上安装开启服务进行管理，也可以在本地开启服务连接云主机，进行管理。不过重要的是kibana的版本号应与elasticsearch的版本号相同。 wget https://artifacts.elastic.co/downloads/kibana/kibana-6.0.0-linux-x86_64.tar.gz tar -zxvf kibana-6.0.0-linux-x86_64.tar.gz ik分词器安装先cd到elasticsearch目录下，然后通过elasticsearch-plugin安装 ./bin/elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v6.0.0/elasticsearch-analysis-ik-6.0.0.zip 配置Elasticsearch配置elasticsearch致力于隐藏分布式复杂的特性，以下操作都是在底层自动完成的： 将文档分区到不同的容器或者分片中，他们可以存在于一个或多个节点中 将分片均匀的分配到各个节点，对索引和搜索做负载均衡 冗余每个分片，防止硬件故障造成的数据丢失 将集群中任意一个节点上的请求路由到相应数据的所在节点 无论是增加节点，还是移除节点，分片都可以做到无缝的扩展和迁移 喵，elasticsearch分布式的细节可以去研究官方文档，如何处理文档存储，如何进行扩展集群和故障转移，如何进行分布式搜索，分片是什么以及如何工作的。当然这些都不懂也是可以使用elasticsearch的 要说elasticsearch的配置，得先搞清楚几个事情。 集群(cluster)由一个或多个节点(node)组成，他们具有相同的cluster.name，它们协同工作，分享数据和负载。当加入新节点或者删除一个节点时，集群就会感知到并平衡数据。 节点(node) 一个Elasticsearch实例，一个机器可以有多个node,大多数情况node运行在一个独立的环境或虚拟机上 索引(index)这里的索引指的不是动词，es有两个index一个是动词建立索引，还有一个是名词，类似于关系型数据库的table。ES和RDB的对应关系如下：RDB =&gt; DB =&gt; Tables =&gt; Rows =&gt; Columns : ES =&gt; Indices =&gt; Types =&gt; Documents =&gt; Fields 分片(shard)ES是分布式搜索引擎，每个索引有一个或多个分片，索引的数据被分配到各个分片上，相当于一桶水用了N个杯子装，也利于横向扩展 集群中一个节点会被选举为主节点(master)，它将临时管理集群级别的一些变更，例如新建或删除索引，增加或移除节点等。主节点不参与文档级别的变更或搜索，这意味着在流量增长的时候，该主节点不会成为集群的瓶颈。 作为用户，我们能够与集群中的任何节点通信，包括主节点。每一个节点都知道文档存在于哪个节点上，它们可以转发请求到相应的节点上。我们访问的节点负责收集各节点返回的数据，最后一起返回给客户端。这一切都由Elasticsearch处理。 再来说说elasticsearch的配置文件elasticsearch.ymlelasticsearch默认启动的集群名字叫elasticsearch。为了安全，最好改个名字。 cluster.name: elasticsearch_production 然后是节点名字，默认会随机指定一个名字，elasticsearch作者增添了一些有趣的名字，可是这并不那么有趣，因为你会搞不清哪台物理机叫什么名字。最主要的是每次重启时，都会得到一个新的名字，这使得日志变得混乱，所以配置节点的名称是非常必要的。 node.name: elasticsearch_001_data 下面这个配置成节点的ip就好 network.host: ip 路径配置，这也是十分必要的，因为默认情况下，elasticsearch会把插件、日志以及数据放在安装目录下，重新安装就会很麻烦。可以通过逗号分隔指定多个目录，如果每个目录分别挂载不同的硬盘，这可是一个简单且高效实现一个软磁盘阵列的办法,和任何磁盘阵列一样一个硬盘坏了，数据也一样会丢失，而且elasticsearch不会将一个分片放在不同的硬盘上，因为一个驱动器的丢失会破坏所有的分片，所以elasticsearch还是将分片放在一个驱动器上。性能的话呢，如果想添加多个驱动器来提高一个单独索引的性能，帮助并不大，因为大多数节点只有一个分片和这样一个积极的驱动器。多个数据路径只是帮助有多个索引/分片再单个节点上喵，如果需要更高级的、稳健的、灵活的配置，还是需要用software RAID软件，而不是多个数据路径的功能 12345path.data: /path/to/data1,/path/to/data2# Path to log files:path.logs: /path/to/logs# Path to where plugins are installed:path.plugins: /path/to/plugins 最小主节点数minimum_master_nodes 设定对你的集群的稳定 极其 重要。 当你的集群中有两个 masters（注：主节点）的时候，这个配置有助于防止 脑裂 ，一种两个主节点同时存在于一个集群的现象。 如果你的集群发生了脑裂，那么你的集群就会处在丢失数据的危险中，因为主节点被认为是这个集群的最高统治者，它决定了什么时候新的索引可以创建，分片是如何移动的等等。如果你有 两个 masters 节点， 你的数据的完整性将得不到保证，因为你有两个节点认为他们有集群的控制权。 这个配置就是告诉 Elasticsearch 当没有足够 master 候选节点的时候，就不要进行 master 节点选举，等 master 候选节点足够了才进行选举。 此设置应该始终被配置为 master 候选节点的法定个数（大多数个）。法定个数就是 ( master 候选节点个数 / 2) + 1 。 这里有几个例子： 如果你有 10 个节点（能保存数据，同时能成为 master），法定数就是 6 。如果你有 3 个候选 master 节点，和 100 个 data 节点，法定数就是 2 ，你只要数数那些可以做 master 的节点数就可以了。如果你有两个节点，你遇到难题了。法定数当然是 2 ，但是这意味着如果有一个节点挂掉，你整个集群就不可用了。 设置成 1 可以保证集群的功能，但是就无法保证集群脑裂了，像这样的情况，你最好至少保证有 3 个节点。你可以在你的 elasticsearch.yml 文件中这样配置： discovery.zen.minimum_master_nodes: 2 具体的还请阅读官方文档有些部分还都不懂(逃，还有配置文件的详解,不过补充一个都没有提及的配置，如何开启外网ip访问？ http.host: 0.0.0.0 这样就能够通过ip加端口号进行访问了。 Kibana配置kibana的配置文件在config目录下，这样就kibana就可以通过外网访问进行管理。1server.host: 0.0.0.0 也可以通过下面这种方式在自己的pc上开启kibana来对ES进行管理1elasticsearch.url: "http://ip:9200" 启动不能用root用户启动elasticsearch，ES由于安全考虑不能使用root权限启动,如果用root启动会报cannot run as root 12345groupadd elasticsearchuseradd elastic -g elasticsearchchown -R -v elastic:elasticsearch elasticsearch-6.0.0su elastic./bin/elasticsearch -d 如果你改变了配置文件中的各种路径，也要给那些路径配置权限，配置方法同上。 最后还要将 kernel 的 vm.max_map_count 设置为 262144。1sysctl -w vm.max_map_count=262144 这样就能够正确启动了，打开另外一个终端测试，如果得到类似的json格式的数据那么就说明搭建成功了 curl ‘http://localhost:9200/?pretty&#39; 123456789101112131415&#123; "name" : "2p_QR4W", "cluster_name" : "elasticsearch_production", "cluster_uuid" : "-Fgpx2fNRx64oiPXblNzOQ", "version" : &#123; "number" : "6.0.0", "build_hash" : "8f0685b", "build_date" : "2017-11-10T18:41:22.859Z", "build_snapshot" : false, "lucene_version" : "7.0.1", "minimum_wire_compatibility_version" : "5.6.0", "minimum_index_compatibility_version" : "5.0.0" &#125;, "tagline" : "You Know, for Search"&#125; ES启动完毕后就可以启动kibana了，cd到kibana目录下 ./bin/kibana 然后打开浏览器访问 http://ip:5601/app/kibana 或者在本地启动kibana服务 http://localhost/app/kibana 懒得截图 集群搭建每台机子按照上述的配置文件进行配置，集群名相同，节点名字有序替换。 然后依次启动机子就好了。 本篇也会随着学习不断更新。]]></content>
      <categories>
        <category>Material</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[相对路径与绝对路径]]></title>
    <url>%2F2017%2F08%2F13%2F%E7%9B%B8%E5%AF%B9%E8%B7%AF%E5%BE%84%E4%B8%8E%E7%BB%9D%E5%AF%B9%E8%B7%AF%E5%BE%84%2F</url>
    <content type="text"><![CDATA[经常在页面中引用图片，html页面等，总结一下绝对路径与相对路径。绝对路径很简单，相对路径的话同级文件夹下不需要在前面加../，其他情况都要加 若引用的资源和本身在同一路径下（既在同一目录下）假设example.html的路径是D:/例子/example.html 假设tupian.gif的路径是D:/例子/tupian.gif 在example.html中引用tupian.gif 相对路径：&lt;img src=&quot;tupian.gif&quot; border=&quot;0&quot;/&gt; 绝对路径：&lt;img src=&quot;d:/例子/html/tupian.gif&quot; border=&quot;0&quot;/&gt; 绝对的都差不多，只说相对路径。 要引用的文件在下一级文件夹下，文件名前加子文件夹名称 假设info.html路径是：c:\Inetpub\wwwroot\sites\blabla\info.html 假设index.html路径是：c:\Inetpub\wwwroot\sites\blabla\html\tutorials\index.html 在info.html加入index.html超链接的href应该这样写：html/tutorials/index.html 要引用的文件在上一级文件夹下，文件名前加../假设info.html路径是：c:\Inetpub\wwwroot\sites\blabla\info.html 假设index.html路径是：c:\Inetpub\wwwroot\sites\index.html 在info.html加入index.html超链接的代码应该这样写： &lt;a href=&quot;../index.html&quot;&gt;index.html&lt;/a&gt; 举一反三： ../表示源文件所在目录的上一级目录，../../表示源文件所在目录的上上级目录，以此类推 更复杂的情况：假设info.html路径是：c:\Inetpub\wwwroot\sites\blabla\info.html 假设index.html路径是：c:\Inetpub\wwwroot\sites\html\index.html 在info.html加入index.html超链接的代码应该这样写： &lt;a href=&quot;../html/index.html&quot;&gt;index.html&lt;/a&gt; 最后一个例子假设路径：D:\例子\html\style\view\pop.css D:\例子\html\images\view\tupian.gif 在css中引用这个图片：&lt;img src=&quot;../../images/view/tupian.gif&quot; border=&quot;0&quot;/&gt;]]></content>
      <categories>
        <category>Material</category>
      </categories>
      <tags>
        <tag>web</tag>
        <tag>Html</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jsp笔记(一)]]></title>
    <url>%2F2017%2F08%2F12%2FJsp%E7%AC%94%E8%AE%B0(%E4%B8%80)%2F</url>
    <content type="text"><![CDATA[小鱼笔记Jsp基本语法 指令标识语法： &lt;%@ 指令名 属性 1=“属性1的值” 属性2=“属性2的值”%&gt; 指令名： page 定义整个页面的相关属性 include 静态包含另外一个Jsp页面 taglib 自定义 &lt;%@ page import=”java.util.*”%&gt; &lt;%@ include file =”path”%&gt; &lt;%@ taglib %&gt; 表达式：1&lt;%= 表达式 %&gt; %与=之间不能有空格，但=后可以有12&lt;% String manager="mr";%&gt;管理员： &lt;%= manager%&gt; 注释html注释1&lt;!--...--&gt; 客户端可见，下载源代码 隐藏注释：1&lt;%-- ..... --%&gt; 隐藏注释不能够从源代码中看到 动态注释：1&lt;!-- &lt;%=new Date()%&gt; --&gt; 包含文件标识：1&lt;jsp:include page="url" flush="false|true"/&gt; 指令存在很大差别12345671. include指令通过file 属性指定被包含的文件，而且file属性不支持任何表达式，而jsp:include通过page属性指定被包含的文件，而且page属性支持JSP表达式。2. include指令是先把被包含文件原封不动的插入到包含页中，然后再有JSP编译器编译成一个Java文件，使用Jsp:include时，分别编译3. include 不能有重名的变量和方法 jsp:include中可以## 请求转发标识```Java&lt;jsp:forward page=&quot;url&quot;/&gt; 传递参数标识1&lt;jsp:param name="参数名" value="参数值"/&gt; 例子123&lt;jsp:forward page="modify.jsp"&gt; &lt;jsp:param name="userid" value="7"/&gt;&lt;/jsp:forward&gt; 9个JSP内置对象request处理HTTP中的各项参数 访问请求参数在页面中定义1&lt;a href="delete.jsp?id=1&amp;user="&gt;删除&lt;/a&gt; 在delete.jsp中获取参数的方法getParameter1234&lt;%String id = request.getParameter("id");String user = request.getParameter("user");%&gt; id为1，user为空但不为null 解决乱码1&lt;%= new String(request.getParameter("name").getBytes("ISO-8859-1")，"UTF-8")%&gt; 所有的request的请求都是通过ISO-8859-1的，而在此页面采用的是UTF-8编码方式，通过上面这种方式可以防止乱码。 作用域中管理属性1request.setAttribute(String name,Object obiect); name变量在request的范围内有效对应方法1request.getAttribute("String name"); getAttribute()方法可以提取请求转发页面setAttribute()传的一些数据，然后对数据进行处理。 获取cookiegetCookies()getName()getValue()addCookie() 获取客户端信息 显示国际化信息request对象中的getLocale()和getLocales()方法允许获得本地语言1234567891011&lt;%Java.util.Locale locale=request.getLocale();String str = "";if(locale.equals(java.util.Locale.US))&#123; str="Hello,welcome to access our company's web!";&#125;if(locale.equals(java.util.Locale.CHINA))&#123; str="您好，欢饮访问我们公司网站!";&#125;%&gt;&lt;%=str%&gt; response响应客户请求，向客户端输出信息 重定向网页1response.sendRedirect(String path); 通过sendRedirect()方法将网页重定向到另一个页面，支持将地址重新定向到不同主机上，这一点与转发不同。在浏览器上重新得到网址，然后重新发送请求链接。重定向操作后，request中的属性全部失效，并且开始一个新的request对象 处理HTTP开头禁用缓存适用于一些安全性较高的网站1234&lt;%response.setHeader("Cache-Control","no-store");response.setDateHeader("Expires",0);%&gt; 页面自动刷新123&lt;%response.setHeader("refresh","10");%&gt; 每隔十秒钟刷新一次 定时跳转网页123&lt;%response.setHeader("refresh","5;URL=login.jsp");%&gt; 5秒后跳向指定网页 设置输出缓冲只有满足一下三种情况之一才会把缓冲区的内容写到客户端 Jsp页面的输出信息已经全部写入到了缓冲区 缓冲区已满 在Jsp页面中，调用了response对象的flushBuffer()方法或out对象的flush()方法 response中对缓冲区进行配置的方法 session通过session可以在应用程序的Web页面间进行跳转时，保存用户的状态，使整个用户会话会一直存在下去，直到关闭浏览器，例如，Tomcat服务器默认为30分钟，不过这个时间可以通过编写程序进行修改 创建及获取客户的会话将信息保存在session范围内1session.setAttribute().setAttribute(String name,Object obj) 获取保存在session范围内的信息1session.getAttribute(String name) 返回的是Object类型，所以要添加toString()方法或强制转换12String user=(String)session.getAttribute("username");String user1=session.getAttribute("username").toString(); 从会话中移动指定的绑定对象1session.removeAttribute(String name) 销毁session虽然session对象过一段时间会自动消失，但对于某些实时统计在线人数的网站（例如聊天室）,所以要手动销毁session来统计准确人数1session.invalidate(); 会话超时管理如果用户超过session存在时间后操作，会报错，为了避免这种现象，所以要对session的有效性进行判断 方法 描述 getlastAccessedTime() 返回客户端最后一次与会话相关联的请求时间 getMaxInactiveInterval() 以秒为单位返回一个会话内两个请求最大的时间间隔 setMaxInactiveInterval() 以秒为单位设置session的有效时间 applicationapplication 用于保存所有应用程序中的公有数据。它在服务器启动时自动创建，在服务器停止时销毁。比session的生命周期更长 访问应用程序初始化参数1application.getInitParameter(String name); 返回已命名的参数值1application.getInitParameterNames(); 返回所有已定义的应用程序初始化参数名的枚举实例：应用getAttributeNames()方法获取web.xml中定义的全部应用程序初始化参数名，并循环输出12345678910&lt;%@ page import="java.util.*"%&gt;&lt;%Enumeration enema = application.getInitParameterNames();while(enema.hasMoreElements())&#123; String name = (String)enema.nextElement(); String value = application.getInitPatameter(name); out.println(name+":"); out.println(value);&#125;%&gt; 管理应用程序环境属性 方法 描述 getAttributeNames() 获取所有application对象使用的属性名 getAttribute(String name) 从application对象中获取指定对象名 getAttribute(String key,Object obj) 使用指定名称和指定对象在application对象中进行关联 removeAttribute(String name) 从application对象中去掉指定名称的属性 outout对象用于在web浏览器内输出信息，并且管理应用服务器上的输出缓冲区 print()方法向客户端浏览器输出信息。通过该方法向客户端浏览器输出信息与使用JSP表达式输出信息相同1234&lt;%out.print("明日科技")%&gt;&lt;%= "明日科技"%&gt; println()方法与print方法不同，在输出内容后，会输出一个换行符 管理影响缓冲out对象比较重要的一个功能 pageContext获取会话范围，通过它可以获取JSP页面的request,session,application,exception config读取web.xml配置信息的config对象，通过getServletConfig()方法可以获取一个config对象，当以个Servlet初始化时，容器吧某些信息通过config对象传给这个Servlet page应答或请求page对象，可以用来当作this关键词的别名 exception获取异常信息，只有在page指令中设置为isErrorPage属性值为true的页面中才可以被使用，在一般的JSP页面中使用该对象无法编译JSP文件。]]></content>
      <categories>
        <category>Material</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Jsp</tag>
        <tag>web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[写在无聊前]]></title>
    <url>%2F2017%2F08%2F03%2F%E5%86%99%E5%9C%A8%E6%97%A0%E8%81%8A%E5%89%8D%2F</url>
    <content type="text"><![CDATA[沉迷Dota2，再加上拖延症，我的瓜皮小站终于在8月3日上线了。在这里会整理积累自己做的东西，发发牢骚和记笔记，技术贴怕是不会有了。希望这个博客能够一直更新下去吧！]]></content>
      <categories>
        <category>Complaint</category>
      </categories>
      <tags>
        <tag>碎碎念</tag>
      </tags>
  </entry>
</search>
